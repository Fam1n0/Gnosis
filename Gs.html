<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Real-Time Edge Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #000;
            color: #fff;
        }
        .container {
            text-align: center;
        }
        video, canvas {
            border: 1px solid #ccc;
            margin-top: 20px;
        }
    </style>
</head>
<body>
<div class="container">
    <h1>Real-Time Edge Detection</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
</div>
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>
<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
    }

    function processVideo() {
        const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        const dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);

        function captureFrame() {
            ctx.drawImage(video, 0, 0, video.width, video.height);
            let imageData = ctx.getImageData(0, 0, video.width, video.height);
            src.data.set(imageData.data);

            cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
            cv.Canny(dst, dst, 50, 100);

            cv.imshow('canvas', dst);
            requestAnimationFrame(captureFrame);
        }
        captureFrame();
    }

    video.addEventListener('play', () => {
        processVideo();
    });

    startCamera();
</script>
</body>
</html>
